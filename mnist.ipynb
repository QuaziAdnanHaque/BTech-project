{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f999d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c95c96",
   "metadata": {},
   "source": [
    "# Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198c8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f070d",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0bae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0  # Normalize to [0,1]\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5f0b6",
   "metadata": {},
   "source": [
    "# One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5c2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e648a",
   "metadata": {},
   "source": [
    "# Split training set into train and validation (80% train, 20% val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d807709",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532f91d",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06502d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37867e9",
   "metadata": {},
   "source": [
    "# Define VGGNet-inspired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "421c6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(28, 28, 1)),\n",
    "\n",
    "        # Block 1\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  # Output for 10 classes\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb27654",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398ecb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_vgg_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf97df6",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fe5f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef81322",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c8b8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haque\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 67ms/step - accuracy: 0.6462 - loss: 0.9669 - val_accuracy: 0.9770 - val_loss: 0.0879\n",
      "Epoch 2/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 67ms/step - accuracy: 0.9749 - loss: 0.0908 - val_accuracy: 0.9890 - val_loss: 0.0410\n",
      "Epoch 3/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 67ms/step - accuracy: 0.9824 - loss: 0.0640 - val_accuracy: 0.9858 - val_loss: 0.0484\n",
      "Epoch 4/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 67ms/step - accuracy: 0.9849 - loss: 0.0548 - val_accuracy: 0.9891 - val_loss: 0.0384\n",
      "Epoch 5/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 67ms/step - accuracy: 0.9866 - loss: 0.0487 - val_accuracy: 0.9837 - val_loss: 0.0606\n",
      "Epoch 6/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 67ms/step - accuracy: 0.9884 - loss: 0.0445 - val_accuracy: 0.9912 - val_loss: 0.0348\n",
      "Epoch 7/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 69ms/step - accuracy: 0.9898 - loss: 0.0405 - val_accuracy: 0.9887 - val_loss: 0.0432\n",
      "Epoch 8/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 70ms/step - accuracy: 0.9892 - loss: 0.0396 - val_accuracy: 0.9898 - val_loss: 0.0402\n",
      "Epoch 9/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 69ms/step - accuracy: 0.9899 - loss: 0.0346 - val_accuracy: 0.9880 - val_loss: 0.0478\n",
      "Epoch 10/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 69ms/step - accuracy: 0.9893 - loss: 0.0386 - val_accuracy: 0.9921 - val_loss: 0.0308\n",
      "Epoch 11/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 68ms/step - accuracy: 0.9904 - loss: 0.0322 - val_accuracy: 0.9892 - val_loss: 0.0420\n",
      "Epoch 12/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 68ms/step - accuracy: 0.9915 - loss: 0.0299 - val_accuracy: 0.9890 - val_loss: 0.0426\n",
      "Epoch 13/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 69ms/step - accuracy: 0.9908 - loss: 0.0317 - val_accuracy: 0.9897 - val_loss: 0.0376\n",
      "Epoch 14/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 68ms/step - accuracy: 0.9919 - loss: 0.0301 - val_accuracy: 0.9851 - val_loss: 0.0573\n",
      "Epoch 15/15\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 69ms/step - accuracy: 0.9915 - loss: 0.0330 - val_accuracy: 0.9918 - val_loss: 0.0319\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    epochs=15,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d86f7e",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517ed2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9932 - loss: 0.0260\n",
      "Test Accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309ba3e",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04db79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"vgg_mnist.h5\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8e48be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('untitled.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0368a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='gray')  # Use cmap='gray' for grayscale images\n",
    "plt.axis('off')  # Hide axis for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a5c042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('untitled.png', cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "img = cv2.resize(img, (28, 28))  # Resize to match model input size\n",
    "img = img / 255.0  # Normalize pixel values to [0,1]\n",
    "img = np.reshape(img, (1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7655b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "519f1994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
